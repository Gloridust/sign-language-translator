# Roadmap
- [x] Old project setup on Git

- [-] Landmarks Utils
    - [x] LandmarksInfo
        - [x] counts
        - [x] connections
        - [x] colors
        - [x] reshaper
    - [x] Visualization (3D)
        - [x] single frame image
        - [x] multiple frames on one image
        - [x] graph video
    - [x] 4D Transformations
        - [x] zoom
        - [x] rotation
        - [x] noise
        - [x] time dialation
        - [x] stabilization/rectification
            - [x] warp video
    - [x] concatenate clips (video/landmarks (concatenative synthesis tts))
        - [x] transitions
        - [x] trimming
    - [ ] test cases

- [-] Video data
    - [x] Cut raw videos
    - [x] utils for video cutting
    - [x] upload / sync
    - [x] completeness check + utility
    - [x] standardize filenames
    - [x] remove duplicate signs
    - [ ] (sign_collection prefix)
    - [ ] clip properties table (including missing/retake, word/sentence, POS, group, data provenence & lineage & meta-data, camera_specs,camera_angle_label,  roll/pitch/yaw)
    - [ ] pose extraction
        - [ ] different versions of mediapipe models
        - [ ] other models (OpenPose)
- [-] text Utils
    - [ ] normalize text
    - [ ] handle numbers
    - [ ] tokenize / phrases (sentencepiece)
    - [ ] embeddings
    - [ ] word error rate / similarity metrics etc
- [-] text data
    - [-] list supported words
    - [-] mappers (word2word, word2embedding)
    - [ ] text2text dataset
    - [-] text corpora mining/scrapping (glosbe, ur.wikipedia, rekhta, jw)
    - [-] language model for data augmentation

- [ ] Web Development (1)
    - [ ] opening/loading page/pic --> Sign Language Translator\n sign animation \n native lang (اشاراتی زبانوں کا ترجمان) (0.25 sec fade-in, stay till animation, 0.25 sec fade-out + pretty font like rekhta.org) (https://fonts.google.com/?subset=arabic&noto.script=Arab&preview.text=%D8%A7%D8%B4%D8%A7%D8%B1%D8%A7%D8%AA%DB%8C%20%D8%B2%D8%A8%D8%A7%D9%86%D9%88%DA%BA%20%DA%A9%D8%A7%20%D8%AA%D8%B1%D8%AC%D9%85%D8%A7%D9%86&preview.text_type=custom) (Aref Ruqaa, Amiri, Scheherazade New)
    - [ ] gentle background music
    - [ ] Website integration with package
    - [ ] Text to Sign page
        - [ ] send synthesized video directly from memory (no IO, use HttpStreaminResponse)
        - [ ] normalize text (keymap)
        - [ ] append response to drop down instead of overwriting
        - click on word to popup video/similar words/definition/picture(generated by dall-e, in style)
    - [ ] Sign to Text page
        - [ ] recorded video fps/preprocessing progress bar
        - [ ] seperate thread for video preprocessing

- [ ] Data loader
    - [ ] data loader class
        - dataframe to path (clip properties table)
        - I/O / download/upload
    - [ ] text to pose/clip ({"<|unk|>": zeros/static}) (class: supported_words, finger_spells, numbers, dates)
    - [ ] batch generator (pytorch)
    - [ ] download data/models

- [ ] Web Development (2)
    - [ ] Website integration with package (video loader/downloader)
    - [x] mirror fill borders of stabilized videos

- [ ] Training ( || research paper)
    - [ ] whisper --> gesture :)
    - [ ] finetune mediapipe
    - [ ] T5 (summarizer) on text2text dataset
    - [ ] pose generation (text 2 audio, (parametric synthesis tts))
        - [ ] evaluation (classifier for machine-generated and human-produced speech, WER on stt model)
    - [ ] motion transfer (.../stable diffusion)
    - [ ] pose to image (GAN/stable diffusion)
- [ ] Deployment
    - [ ] API / MLOps / model & video persistance in memory
    - [ ] finalize dataset structure/storage
    - [ ] add verified file descriptions to google drive video dataset (PSL sign video for words: ... collected at hamza foundation lahore)
- [ ] monitoring Utils

- [ ] Web Development (3)
    - [ ] Documentation page like https://spacy.io/api/matcher
    - [ ] Website integration with package (models)
    - [ ] Text to Sign page
        - [ ] text writing tool with drop-down suggestions of supported words
        - [ ] supported word linting (green box)
        - [ ] + button --> dropdown of languages --> append text editor (popped from dropdown) --> has x button except for last, also change language button (also adjust dropdown)
        - [ ] avatar (three.js, 3d/2d cartoon)
    - [ ] Sign to Text page
        - [ ] previous request/response list/grid
        - [ ] landmark graphs (2D/3D) (https://openai.com/blog/introducing-text-and-code-embeddings -> Text similarity models, https://projector.tensorflow.org/)
    - [ ] Data Collection page
        - [ ] free to use but register to submit (need location, language info, non-spam, local/S3 storage etc)
        - [ ] voting system to standardize global/national language. Suggest sign using AI. Select concept/word in all languages, select global/nation to standardize--> show all reference clips with regions as bubble chart + check box to vote
        - [ ] text corpus
            - [ ] Writing pad for sentences of supported words. dropdown of supported words. Substitutable word groups in drop-up to create multiple sentence at once (expand/multiply group button, submit button)
            - [ ] display vocab and existing sentence lists.
            - [ ] display word suggestions to write about as buttons (inverse frequency sampling).
            - [ ] check synthetic sentences. append to list batch submit.
        - [ ] parallel corpus --> English+Native, google translate, suggested tokens as buttons (in sequence, 2D positions - horizontal for text direction, vertical for probability of being next)
            - [ ] sentence tokenizer for books/paragraph corpus upload.
        - [ ] Sign Videos
            - [ ] upload reference clips / manage db
            - [ ] reference clips labels (filename, synonyms)
            - [ ] display reference clips (loop, prev, next), start/stop recording, mark timestamps
            - [ ] display texts (words/sentences) and record. (show full sentence -> perform in PSL structure --> transcribe the signs = full 2 gloss data)
            - [ ] annotate the recording (sliders (initialized at timestamps, slide, lock) + textboxes (transcription and translation))
            - [ ] label unlabeled clips.
- [ ] Show off results to Hamza Foundation, get feedback
    - [ ] data collection
        - [ ] verify and improve word2file dict
            - [ ] google drive file descriptions (see above)
        - [ ] text restructuring dataset (parallel spreadsheet) + (show full sentence -> perform in PSL structure --> transcribe the signs = full 2 gloss data)
        - [ ] sign language videos dataset
- [ ] Training ( || research paper)
    - [ ] activity recognition/generation
    - [ ] better embedding model
- [ ] ★ Publish Research Paper & Datasets ★
- [ ] Raise Awareness, Hand over the project.
- [ ] Start living life again.


## Todo:
- add a clip info table, fps resolution etc
- test reshaper on single frame
- test scale_landmarks in T.stabilize_clips()

### monitering
- average input length
- average image brightness
- average hidden landmarks
- average hand position/distances
- number of times null output
- number of time quick consequtive similar input
- when user quits
- CTR
- Dashboard
- activity detection --> trim video